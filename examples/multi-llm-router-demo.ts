/**
 * Multi-LLM Router Demo
 * Demonstrates the intelligent LLM routing system with OpenAI, Gemini, and Claude
 */

import { LLMRouter } from '../src/main/js/llm/router';
import type { ChatRequest } from '../src/main/js/llm/providers/base-provider';

// Configuration
const config = {
  openaiKey: process.env.OPENAI_API_KEY || '',
  geminiKey: process.env.GOOGLE_API_KEY || '',
  claudeKey: process.env.ANTHROPIC_API_KEY || '',
};

/**
 * Demo 1: Automatic Provider Selection (Balanced Strategy)
 */
async function demo1_BalancedRouting() {
  console.log('\n========================================');
  console.log('Demo 1: æ™ºèƒ½è·¯ç”±ï¼ˆBalanced ç­–ç•¥ï¼‰');
  console.log('========================================\n');

  const router = new LLMRouter(
    config.openaiKey,
    config.geminiKey,
    config.claudeKey,
    { strategy: 'balanced', fallbackEnabled: true, maxRetries: 2 }
  );

  // Test cases with different complexity levels
  const testCases = [
    {
      name: 'ç°¡å–®æŸ¥è©¢',
      messages: [{ role: 'user' as const, content: 'ä»€éº¼æ˜¯ TypeScript?' }],
      expectedProvider: 'Gemini (ä¾¿å®œ/å…è²»)',
    },
    {
      name: 'è¤‡é›œæŸ¥è©¢',
      messages: [
        {
          role: 'user' as const,
          content: `è¨­è¨ˆä¸€å€‹åˆ†æ•£å¼ç³»çµ±çš„æ¶æ§‹ï¼Œéœ€è¦è€ƒæ…®ï¼š
            1. å¾®æœå‹™æ¶æ§‹
            2. æ•¸æ“šåº«åˆ†ç‰‡ç­–ç•¥
            3. è² è¼‰å‡è¡¡
            4. å®¹éŒ¯æ©Ÿåˆ¶
            5. æ€§èƒ½å„ªåŒ–
            è«‹æä¾›è©³ç´°çš„è¨­è¨ˆæ–¹æ¡ˆå’Œå¯¦ç¾æ­¥é©Ÿã€‚`,
        },
      ],
      expectedProvider: 'OpenAI (è¤‡é›œæŸ¥è©¢) æˆ– Claude (é«˜è¤‡é›œåº¦)',
    },
    {
      name: 'å®‰å…¨ä»»å‹™',
      messages: [
        {
          role: 'user' as const,
          content: 'å¦‚ä½•å¯¦ç¾ JWT authentication å’Œ Row Level Security (RLS)?',
        },
      ],
      expectedProvider: 'Claude (å®‰å…¨ä»»å‹™)',
    },
    {
      name: 'UI ä»»å‹™',
      messages: [
        {
          role: 'user' as const,
          content: 'å‰µå»ºä¸€å€‹ React çµ„ä»¶ä¾†é¡¯ç¤ºç”¨æˆ¶åˆ—è¡¨ï¼Œéœ€è¦æ”¯æ´æœç´¢å’Œåˆ†é åŠŸèƒ½',
        },
      ],
      expectedProvider: 'OpenAI (UI ä»»å‹™)',
    },
  ];

  for (const testCase of testCases) {
    console.log(`ğŸ“‹ ä»»å‹™: ${testCase.name}`);
    console.log(`   é æœŸé¸æ“‡: ${testCase.expectedProvider}`);

    try {
      const request: ChatRequest = {
        messages: testCase.messages,
        temperature: 0.7,
      };

      const response = await router.createChatCompletion(request);

      console.log(`   âœ… å¯¦éš›é¸æ“‡: ${response.provider}`);
      console.log(`   æ¨¡å‹: ${response.model}`);
      console.log(`   Token: ${response.usage.total_tokens}`);
      console.log(`   æˆæœ¬: $${response.cost.toFixed(6)}`);
      console.log(`   å›æ‡‰æ‘˜è¦: ${response.message.content.substring(0, 80)}...`);
      console.log();
    } catch (error: any) {
      console.error(`   âŒ éŒ¯èª¤: ${error.message}\n`);
    }
  }
}

/**
 * Demo 2: Cost Optimization Strategy
 */
async function demo2_CostStrategy() {
  console.log('\n========================================');
  console.log('Demo 2: æˆæœ¬å„ªåŒ–ç­–ç•¥');
  console.log('========================================\n');

  const router = new LLMRouter(
    config.openaiKey,
    config.geminiKey,
    config.claudeKey,
    { strategy: 'cost', fallbackEnabled: true, maxRetries: 2 }
  );

  const tasks = [
    'å¯«ä¸€å€‹æ’åºå‡½æ•¸',
    'è§£é‡‹ä»€éº¼æ˜¯éæ­¸',
    'å‰µå»ºä¸€å€‹ TODO List æ‡‰ç”¨',
  ];

  let totalCost = 0;

  for (const task of tasks) {
    console.log(`ğŸ“‹ ä»»å‹™: ${task}`);

    try {
      const response = await router.createChatCompletion({
        messages: [{ role: 'user', content: task }],
      });

      console.log(`   Provider: ${response.provider}`);
      console.log(`   æˆæœ¬: $${response.cost.toFixed(6)}`);
      console.log(`   Token: ${response.usage.total_tokens}`);
      console.log();

      totalCost += response.cost;
    } catch (error: any) {
      console.error(`   âŒ éŒ¯èª¤: ${error.message}\n`);
    }
  }

  console.log(`ğŸ’° ç¸½æˆæœ¬: $${totalCost.toFixed(6)}`);
  console.log(`ğŸ’¡ æˆæœ¬ç­–ç•¥: å„ªå…ˆä½¿ç”¨ Gemini (å…è²»/ä¾¿å®œ)`);
}

/**
 * Demo 3: Performance Strategy
 */
async function demo3_PerformanceStrategy() {
  console.log('\n========================================');
  console.log('Demo 3: æ€§èƒ½å„ªå…ˆç­–ç•¥');
  console.log('========================================\n');

  const router = new LLMRouter(
    config.openaiKey,
    config.geminiKey,
    config.claudeKey,
    { strategy: 'performance', fallbackEnabled: true, maxRetries: 2 }
  );

  console.log('ğŸ“‹ ä»»å‹™: è¤‡é›œçš„ä»£ç¢¼ç”Ÿæˆ');

  try {
    const startTime = Date.now();

    const response = await router.createChatCompletion({
      messages: [
        {
          role: 'user',
          content: 'å‰µå»ºä¸€å€‹å®Œæ•´çš„ REST APIï¼ŒåŒ…å«ç”¨æˆ¶èªè­‰ã€CRUD æ“ä½œå’ŒéŒ¯èª¤è™•ç†',
        },
      ],
      temperature: 0.3,
    });

    const duration = Date.now() - startTime;

    console.log(`   âœ… Provider: ${response.provider} (æ€§èƒ½å„ªå…ˆ)`);
    console.log(`   æ¨¡å‹: ${response.model}`);
    console.log(`   åŸ·è¡Œæ™‚é–“: ${duration}ms`);
    console.log(`   Token: ${response.usage.total_tokens}`);
    console.log(`   æˆæœ¬: $${response.cost.toFixed(6)}`);
    console.log(`   ä»£ç¢¼é•·åº¦: ${response.message.content.length} å­—å…ƒ`);
  } catch (error: any) {
    console.error(`   âŒ éŒ¯èª¤: ${error.message}`);
  }
}

/**
 * Demo 4: Automatic Fallback
 */
async function demo4_AutomaticFallback() {
  console.log('\n========================================');
  console.log('Demo 4: è‡ªå‹• Fallback æ©Ÿåˆ¶');
  console.log('========================================\n');

  // ä½¿ç”¨ç„¡æ•ˆçš„ OpenAI key ä¾†è§¸ç™¼ fallback
  const router = new LLMRouter(
    'invalid-key', // æ•…æ„ä½¿ç”¨ç„¡æ•ˆ key
    config.geminiKey,
    config.claudeKey,
    {
      strategy: 'performance', // æ€§èƒ½ç­–ç•¥æœƒå„ªå…ˆé¸ OpenAI
      fallbackEnabled: true,
      maxRetries: 1, // æ¸›å°‘é‡è©¦æ¬¡æ•¸ä»¥åŠ å¿« demo
    }
  );

  console.log('ğŸ“‹ ä»»å‹™: ç°¡å–®å•ç­”');
  console.log('   Primary: OpenAI (ä½¿ç”¨ç„¡æ•ˆ key)');
  console.log('   Fallback: Gemini or Claude\n');

  try {
    const response = await router.createChatCompletion({
      messages: [{ role: 'user', content: 'Hello!' }],
    });

    console.log(`   âœ… Fallback æˆåŠŸï¼`);
    console.log(`   å¯¦éš›ä½¿ç”¨: ${response.provider}`);
    console.log(`   æ¨¡å‹: ${response.model}`);
    console.log(`   å›æ‡‰: ${response.message.content.substring(0, 50)}...`);
  } catch (error: any) {
    console.error(`   âŒ Fallback ä¹Ÿå¤±æ•—: ${error.message}`);
  }
}

/**
 * Demo 5: Health Check and Statistics
 */
async function demo5_HealthAndStats() {
  console.log('\n========================================');
  console.log('Demo 5: å¥åº·æª¢æŸ¥èˆ‡çµ±è¨ˆ');
  console.log('========================================\n');

  const router = new LLMRouter(
    config.openaiKey,
    config.geminiKey,
    config.claudeKey,
    { strategy: 'balanced', fallbackEnabled: true, maxRetries: 2 }
  );

  // Execute some requests first
  console.log('åŸ·è¡Œå¹¾å€‹è«‹æ±‚ä»¥ç´¯ç©çµ±è¨ˆ...\n');

  const tasks = ['Hello', 'TypeScript æ˜¯ä»€éº¼ï¼Ÿ', 'è¨­è¨ˆä¸€å€‹ç³»çµ±æ¶æ§‹'];

  for (const task of tasks) {
    try {
      await router.createChatCompletion({
        messages: [{ role: 'user', content: task }],
      });
    } catch (error) {
      // Ignore errors
    }
  }

  // Get health status
  console.log('ğŸ“Š å¥åº·æª¢æŸ¥:');
  const healthStatus = await router.getHealthStatus();

  for (const [provider, health] of Object.entries(healthStatus)) {
    console.log(`   ${provider}:`);
    console.log(`      ç‹€æ…‹: ${health.healthy ? 'âœ… å¥åº·' : 'âŒ ä¸å¥åº·'}`);
    console.log(`      å»¶é²: ${health.latency}ms`);
  }

  // Get usage stats
  console.log('\nğŸ“ˆ ä½¿ç”¨çµ±è¨ˆ:');
  const stats = router.getUsageStats();

  for (const [provider, stat] of Object.entries(stats)) {
    console.log(`   ${provider}:`);
    console.log(`      è«‹æ±‚æ•¸: ${stat.requests}`);
    console.log(`      å¥åº·: ${stat.healthy ? 'âœ…' : 'âŒ'}`);
  }
}

/**
 * Demo 6: Embedding with Cost Optimization
 */
async function demo6_EmbeddingOptimization() {
  console.log('\n========================================');
  console.log('Demo 6: Embedding æˆæœ¬å„ªåŒ–');
  console.log('========================================\n');

  const router = new LLMRouter(
    config.openaiKey,
    config.geminiKey,
    config.claudeKey,
    { strategy: 'cost', fallbackEnabled: true, maxRetries: 2 }
  );

  const texts = [
    'TypeScript is a typed superset of JavaScript',
    'React is a JavaScript library for building user interfaces',
    'Next.js is a React framework for production',
  ];

  console.log('ğŸ“‹ ç”Ÿæˆ Embeddings (Cost ç­–ç•¥)\n');

  let totalCost = 0;

  for (const text of texts) {
    try {
      const response = await router.createEmbedding({
        input: text,
      });

      console.log(`   âœ… Provider: ${response.provider}`);
      console.log(`   æ¨¡å‹: ${response.model}`);
      console.log(`   ç¶­åº¦: ${response.embedding.length}`);
      console.log(`   Token: ${response.usage.total_tokens}`);
      console.log(`   æˆæœ¬: $${response.cost.toFixed(6)}`);
      console.log();

      totalCost += response.cost;
    } catch (error: any) {
      console.error(`   âŒ éŒ¯èª¤: ${error.message}\n`);
    }
  }

  console.log(`ğŸ’° ç¸½æˆæœ¬: $${totalCost.toFixed(6)}`);
  console.log(`ğŸ’¡ Gemini embeddings å…è²»ï¼`);
}

/**
 * Main execution
 */
async function main() {
  console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
  console.log('â•‘  Multi-LLM Router Demo                 â•‘');
  console.log('â•‘  OpenAI + Gemini + Claude æ™ºèƒ½è·¯ç”±    â•‘');
  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

  // Check API keys
  if (!config.openaiKey) {
    console.error('\nâŒ éŒ¯èª¤: OPENAI_API_KEY æœªè¨­ç½®');
    console.log('æç¤º: export OPENAI_API_KEY=sk-...');
  }
  if (!config.geminiKey) {
    console.error('\nâŒ éŒ¯èª¤: GOOGLE_API_KEY æœªè¨­ç½®');
    console.log('æç¤º: export GOOGLE_API_KEY=AIza...');
  }
  if (!config.claudeKey) {
    console.warn('\nâš ï¸  è­¦å‘Š: ANTHROPIC_API_KEY æœªè¨­ç½®ï¼ˆå¯é¸ï¼‰');
  }

  if (!config.openaiKey || !config.geminiKey) {
    console.log('\nè«‹è¨­ç½®å¿…è¦çš„ API keys å¾Œé‡è©¦ã€‚');
    return;
  }

  try {
    // Run all demos
    await demo1_BalancedRouting();
    // await demo2_CostStrategy();
    // await demo3_PerformanceStrategy();
    // await demo4_AutomaticFallback();
    // await demo5_HealthAndStats();
    // await demo6_EmbeddingOptimization();

    console.log('\n\nâœ… æ‰€æœ‰ç¤ºç¯„å®Œæˆï¼');
    console.log('\nğŸ’¡ æç¤º:');
    console.log('   - å–æ¶ˆè¨»è§£å…¶ä»– demo å‡½æ•¸ä¾†æ¸¬è©¦æ›´å¤šåŠŸèƒ½');
    console.log('   - ä¿®æ”¹ strategy åƒæ•¸ä¾†æ¸¬è©¦ä¸åŒè·¯ç”±ç­–ç•¥');
    console.log('   - æŸ¥çœ‹ router.ts äº†è§£æ™ºèƒ½è·¯ç”±é‚è¼¯');
  } catch (error: any) {
    console.error('\nâŒ éŒ¯èª¤:', error.message);
    console.error(error.stack);
  }
}

// Execute if run directly
if (require.main === module) {
  main();
}

export {
  demo1_BalancedRouting,
  demo2_CostStrategy,
  demo3_PerformanceStrategy,
  demo4_AutomaticFallback,
  demo5_HealthAndStats,
  demo6_EmbeddingOptimization,
};
