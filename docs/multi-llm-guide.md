# ğŸ¤– å¤š LLM æ™ºèƒ½è·¯ç”±ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æ­¤ç³»çµ±æ”¯æ´åŒæ™‚ä½¿ç”¨ **OpenAI** å’Œ **Google Gemini** APIï¼Œä¸¦é€éæ™ºèƒ½è·¯ç”±è‡ªå‹•é¸æ“‡æœ€ä½³ Providerã€‚

## âœ¨ ä¸»è¦å„ªå‹¢

### ğŸ’° **æˆæœ¬å„ªåŒ–**
- Gemini Embeddings: **å…è²»** (vs OpenAI $0.02/1M tokens)
- Gemini 2.0 Flash: **å…è²»** å¯¦é©—ç‰ˆæœ¬ (vs OpenAI $0.15/1M tokens)
- Gemini 1.5 Flash 8B: **$0.0375/1M** (vs OpenAI $0.15/1M tokens)
- **é æœŸç¯€çœ: 50%-100%**

### ğŸ”„ **è‡ªå‹•å®¹éŒ¯**
- Provider æ•…éšœæ™‚è‡ªå‹•åˆ‡æ›
- é‡è©¦æ©Ÿåˆ¶ (æœ€å¤š 2 æ¬¡)
- å¥åº·ç‹€æ…‹ç›£æ§

### ğŸ¯ **æ™ºèƒ½é¸æ“‡**
- æ ¹æ“šä»»å‹™è¤‡é›œåº¦è‡ªå‹•é¸æ“‡
- è² è¼‰å¹³è¡¡
- æ€§èƒ½è¿½è¹¤

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1ï¸âƒ£ **ç²å– API Keys**

#### OpenAI API Key
1. å‰å¾€ https://platform.openai.com/api-keys
2. å»ºç«‹æ–°çš„ API Key
3. è¤‡è£½ Key (sk-...)

#### Gemini API Key (å…è²»)
1. å‰å¾€ https://aistudio.google.com/app/apikey
2. é»æ“Š "Get API Key"
3. è¤‡è£½ Key

### 2ï¸âƒ£ **é…ç½®ç’°å¢ƒè®Šæ•¸**

ç·¨è¼¯ `.env` æª”æ¡ˆï¼š

```bash
# ==========================================
# LLM API Configuration
# ==========================================
OPENAI_API_KEY=sk-your-openai-key-here
GEMINI_API_KEY=your-gemini-key-here

# LLM Router é…ç½®
LLM_STRATEGY=balanced           # cost | performance | balanced
PREFERRED_PROVIDER=             # openai | gemini (ç•™ç©ºè‡ªå‹•é¸æ“‡)
USE_LLM_ROUTER=true            # å•Ÿç”¨æ™ºèƒ½è·¯ç”±
```

### 3ï¸âƒ£ **é¸æ“‡è·¯ç”±ç­–ç•¥**

#### æˆæœ¬å„ªåŒ–æ¨¡å¼ (cost) - å®Œå…¨å…è²»
```bash
LLM_STRATEGY=cost
PREFERRED_PROVIDER=gemini
```
- âœ… æ‰€æœ‰ embeddings ä½¿ç”¨ Gemini (å…è²»)
- âœ… æ‰€æœ‰ chat ä½¿ç”¨ Gemini (å…è²»)
- ğŸ’° **æˆæœ¬: $0/æœˆ**

#### å¹³è¡¡æ¨¡å¼ (balanced) - æ¨è–¦ â­
```bash
LLM_STRATEGY=balanced
PREFERRED_PROVIDER=
```
- âœ… Embeddings: Gemini (å…è²»)
- âœ… ç°¡å–®æŸ¥è©¢ (<1000å­—): Gemini (å…è²»)
- âœ… è¤‡é›œæŸ¥è©¢ (>1000å­—): OpenAI (æ›´å¥½å“è³ª)
- ğŸ’° **æˆæœ¬: ~$2-8/æœˆ (çœ 70%)**

#### æ€§èƒ½æ¨¡å¼ (performance) - å“è³ªå„ªå…ˆ
```bash
LLM_STRATEGY=performance
PREFERRED_PROVIDER=openai
```
- âœ… æ‰€æœ‰è«‹æ±‚ä½¿ç”¨ OpenAI
- âœ… Gemini ä½œç‚ºå‚™æ´
- ğŸ’° **æˆæœ¬: ~$10-20/æœˆ**

---

## ğŸ“Š **ä½¿ç”¨ç¯„ä¾‹**

### åœ¨ä»£ç¢¼ä¸­ä½¿ç”¨

RAG Engine æœƒè‡ªå‹•ä½¿ç”¨ LLM Router:

```typescript
import { RAGEngine } from './core/rag-engine';

// åˆå§‹åŒ– RAG Engine
const ragEngine = new RAGEngine(env, {
  llmStrategy: 'balanced',        // è·¯ç”±ç­–ç•¥
  preferredProvider: undefined,   // è‡ªå‹•é¸æ“‡
  useLLMRouter: true,            // å•Ÿç”¨è·¯ç”±
});

// è‡ªå‹•ä½¿ç”¨æœ€ä½³ LLM
const result = await ragEngine.generateAnswer({
  query: 'ä»€éº¼æ˜¯ AI Agent?',
  top_k: 5,
});

// ç³»çµ±æœƒè‡ªå‹•:
// 1. ä½¿ç”¨ Gemini å‰µå»º embedding (å…è²»)
// 2. æ ¹æ“šæŸ¥è©¢è¤‡é›œåº¦é¸æ“‡ LLM
// 3. å¦‚æœå¤±æ•—ï¼Œè‡ªå‹•åˆ‡æ›åˆ°å‚™æ´ Provider
```

### ç›´æ¥ä½¿ç”¨ LLM Router

```typescript
import { LLMRouter } from './llm/router';

// åˆå§‹åŒ– Router
const router = new LLMRouter(
  env.OPENAI_API_KEY,
  env.GEMINI_API_KEY,
  {
    strategy: 'cost',
    fallbackEnabled: true,
    maxRetries: 2,
  }
);

// å‰µå»º Embedding (è‡ªå‹•é¸æ“‡æœ€ä¾¿å®œçš„)
const embedding = await router.createEmbedding({
  text: 'Hello World',
});

// èŠå¤©è£œå…¨ (è‡ªå‹•é¸æ“‡)
const response = await router.createChatCompletion({
  messages: [
    { role: 'user', content: 'ä½ å¥½' },
  ],
});

// æŸ¥çœ‹ä½¿ç”¨çµ±è¨ˆ
const stats = router.getUsageStats();
console.log(stats);
// {
//   openai: { requests: 50, healthy: true },
//   gemini: { requests: 150, healthy: true }
// }
```

---

## ğŸ“ˆ **ç›£æ§å’Œé™¤éŒ¯**

### æŸ¥çœ‹å¥åº·ç‹€æ…‹

```typescript
const health = await router.getHealthStatus();
console.log(health);
// {
//   openai: { provider: 'openai', healthy: true, latency: 150 },
//   gemini: { provider: 'gemini', healthy: true, latency: 80 }
// }
```

### æŸ¥çœ‹ä½¿ç”¨çµ±è¨ˆ

```typescript
const stats = router.getUsageStats();
console.log(`OpenAI requests: ${stats.openai.requests}`);
console.log(`Gemini requests: ${stats.gemini.requests}`);
```

### æ—¥èªŒè¼¸å‡º

ç³»çµ±æœƒè‡ªå‹•è¨˜éŒ„:
```
âœ… LLM Router initialized (strategy: balanced)
ğŸ“Š Embedding created via LLM Router (model: text-embedding-004, tokens: 50)
ğŸ’¬ Chat completion via LLM Router (model: gemini-2.0-flash-exp, tokens: 200)
âš ï¸ OpenAI failed, falling back to Gemini
```

---

## ğŸ”§ **é€²éšé…ç½®**

### è‡ªè¨‚æ¨¡å‹

```typescript
const ragEngine = new RAGEngine(env, {
  embeddingModel: 'text-embedding-3-large',  // OpenAI é«˜ç²¾åº¦
  chatModel: 'gemini-1.5-pro',               // Gemini Pro
  llmStrategy: 'balanced',
});
```

### ç¦ç”¨è‡ªå‹•è·¯ç”±

å¦‚æœåªæƒ³ç”¨å–®ä¸€ Provider:

```bash
USE_LLM_ROUTER=false
PREFERRED_PROVIDER=openai
```

æˆ–åœ¨ä»£ç¢¼ä¸­:

```typescript
const ragEngine = new RAGEngine(env, {
  useLLMRouter: false,  // ç¦ç”¨è·¯ç”±ï¼Œç›´æ¥ä½¿ç”¨ OpenAI
});
```

---

## ğŸ’¡ **æœ€ä½³å¯¦è¸**

### é–‹ç™¼ç’°å¢ƒ
```bash
LLM_STRATEGY=cost
PREFERRED_PROVIDER=gemini
# ä½¿ç”¨å…è²»é¡åº¦é€²è¡Œé–‹ç™¼å’Œæ¸¬è©¦
```

### ç”Ÿç”¢ç’°å¢ƒ (å¹³è¡¡)
```bash
LLM_STRATEGY=balanced
PREFERRED_PROVIDER=
# è‡ªå‹•é¸æ“‡ï¼Œå…¼é¡§æˆæœ¬å’Œå“è³ª
```

### é«˜æµé‡å ´æ™¯
```bash
LLM_STRATEGY=cost
PREFERRED_PROVIDER=gemini
# æ¸›å°‘æˆæœ¬ï¼Œä½¿ç”¨ Gemini è™•ç†å¤§éƒ¨åˆ†è«‹æ±‚
```

### é—œéµæ¥­å‹™
```bash
LLM_STRATEGY=performance
PREFERRED_PROVIDER=openai
# ç¢ºä¿æœ€ä½³å“è³ª
```

---

## â“ **å¸¸è¦‹å•é¡Œ**

### Q: Gemini çœŸçš„å…è²»å—ï¼Ÿ
A: æ˜¯çš„ï¼Gemini 2.0 Flash (å¯¦é©—ç‰ˆ) å’Œ text-embedding-004 ç›®å‰å®Œå…¨å…è²»ã€‚

### Q: å¦‚æœå…©å€‹ Provider éƒ½å¤±æ•—æ€éº¼è¾¦ï¼Ÿ
A: ç³»çµ±æœƒæ‹‹å‡ºéŒ¯èª¤ï¼Œä¸¦åœ¨æ—¥èªŒä¸­è¨˜éŒ„è©³ç´°è³‡è¨Šã€‚

### Q: å¯ä»¥åªç”¨ Gemini å—ï¼Ÿ
A: å¯ä»¥ï¼è¨­å®š `PREFERRED_PROVIDER=gemini` å’Œ `LLM_STRATEGY=cost`ã€‚

### Q: å¦‚ä½•ç¢ºä¿è³‡æ–™éš±ç§ï¼Ÿ
A: OpenAI å’Œ Gemini éƒ½ä¸æœƒå„²å­˜ API è«‹æ±‚æ•¸æ“šç”¨æ–¼è¨“ç·´ã€‚å»ºè­°æŸ¥é–±å„è‡ªçš„éš±ç§æ”¿ç­–ã€‚

### Q: è·¯ç”±æ±ºç­–çš„å»¶é²æ˜¯å¤šå°‘ï¼Ÿ
A: è·¯ç”±æ±ºç­–æ˜¯æœ¬åœ°è¨ˆç®—ï¼Œå»¶é² <1msã€‚ä¸»è¦å»¶é²ä¾†è‡ª API èª¿ç”¨æœ¬èº«ã€‚

---

## ğŸ“š **åƒè€ƒè³‡æ–™**

- [OpenAI API æ–‡æª”](https://platform.openai.com/docs)
- [Gemini API æ–‡æª”](https://ai.google.dev/docs)
- [æˆæœ¬åˆ†æå ±å‘Š](../COST-ANALYSIS.md)

---

**æ›´æ–°æ™‚é–“:** 2025-10-04
**ä½œè€…:** AI Agent Team
